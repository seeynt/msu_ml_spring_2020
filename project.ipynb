{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import codecs, collections, csv, pymorphy2, re\n",
    "\n",
    "from time import gmtime, strftime, time\n",
    "from bs4 import BeautifulSoup\n",
    "from scipy.spatial import distance\n",
    "from sklearn import linear_model, metrics, model_selection, preprocessing, svm, ensemble, neighbors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from functools import wraps\n",
    "from stop_words import get_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lib:\n",
    "    def process_titles():\n",
    "        data = {}\n",
    "        with open('docs_titles.tsv') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                if i == 0:\n",
    "                    continue\n",
    "                content = line.strip().split('\\t', 1)\n",
    "                doc_id = int(content[0])\n",
    "                if len(content) == 1:\n",
    "                    title = ''\n",
    "                else:\n",
    "                    title = content[1]\n",
    "                data[doc_id] = title\n",
    "        return pd.Series(data)\n",
    "    \n",
    "    train_data = pd.read_csv('train_groups.csv')\n",
    "    test_data = pd.read_csv('test_groups.csv')\n",
    "    titles = process_titles()\n",
    "    g_arange = {\n",
    "        'train': np.arange(1, 130),\n",
    "        'test': np.arange(130, 310),\n",
    "    }\n",
    "    \n",
    "    log_path = 'data/'\n",
    "    features_path = lambda group_id: 'data/f_{}.npy'.format(group_id)\n",
    "    target_path = lambda group_id: 'data/t_{}.npy'.format(group_id)\n",
    "    lxml_str = lambda lxml: ''.join(map(lambda x: ' ' + x.text, lxml.find_all(re.compile('^h[1-6]$'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "class consts:\n",
    "    max_features = 20\n",
    "    title_weight = 3\n",
    "    threshold = 0.35\n",
    "    \n",
    "    function_words = {'INTJ', 'PRCL', 'CONJ', 'PREP'}\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    separators = [';', ':', '-', '_', '|', ',',\n",
    "                  '.', '!', '?', '«', '»', '\"',\n",
    "                  '(', ')', '[', ']', '–', '”',\n",
    "                  '*', '�', '^', '=', '©', '“',\n",
    "                  '’', '+', '…', '&', '—', '$',\n",
    "                  '/', '→', '←', '{', '}', '`',\n",
    "                  '°', '@', '#',\n",
    "                  '\\n', '\\t', '\\r', '\\'', '\\\\']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(text, separators = consts.separators):\n",
    "    text = text.lower()\n",
    "    for sep in separators:\n",
    "        text = text.replace(sep, ' ')\n",
    "    return text.split()\n",
    "\n",
    "def normalizer(text):\n",
    "    text = split(text)\n",
    "    text = list(filter(lambda x: consts.morph.parse(x)[0].tag.POS not in consts.function_words, text))\n",
    "    text = list(filter(lambda x: x not in get_stop_words('russian'), text))\n",
    "    text = list(filter(lambda x: x not in get_stop_words('english'), text))\n",
    "    text = list(map(lambda x: consts.morph.parse(x)[0].normal_form, text))\n",
    "    text = list(map(lambda x: x.replace('ё', 'е'), text))\n",
    "    text = list(filter(lambda x: not re.search('\\d+', x) and len(x) > 1, text))\n",
    "    return ' '.join(text)\n",
    "\n",
    "def doc_handler(doc_id):\n",
    "    path = 'content/{}.dat'.format(doc_id)\n",
    "    with codecs.open(path, 'r', 'utf-8') as f:\n",
    "        url = f.readline().strip()\n",
    "        text = normalizer(lib.lxml_str(BeautifulSoup(f, 'lxml')) + consts.title_weight * (' ' + lib.titles[doc_id]))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logger(func):\n",
    "    f_log = open(lib.log_path + 'report.logs', 'w')\n",
    "    @wraps(func)\n",
    "    def wrapper(mode):\n",
    "        timer = time()\n",
    "        result = func(mode)\n",
    "        print('mode:', mode, file=f_log)\n",
    "        print('time:', strftime('%H:%M:%S', gmtime(np.round(time() - timer))), file=f_log)\n",
    "        print('max_features =', consts.max_features, file=f_log)\n",
    "        print('title_weigh =', consts.title_weight, file=f_log)\n",
    "        print('\\n', file=f_log)\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "def export_data(mode, group_id):\n",
    "    if mode == 'train':\n",
    "        docs = [doc_handler(doc) for doc in \n",
    "                         lib.train_data[lib.train_data.group_id == group_id].doc_id]\n",
    "        data = TfidfVectorizer().fit_transform(docs).todense()\n",
    "        \n",
    "    elif mode == 'test':\n",
    "        docs = [doc_handler(doc) for doc in \n",
    "                         lib.test_data[lib.test_data.group_id == group_id].doc_id]\n",
    "        data = TfidfVectorizer().fit_transform(docs).todense()\n",
    "        \n",
    "    dist = distance.pdist(data, metric = 'cosine')\n",
    "    dist[np.where(np.isnan(dist))[0]] = 1.0\n",
    "    dist = distance.squareform(dist)\n",
    "    \n",
    "    np.save(lib.features_path(group_id), \n",
    "            np.sort(np.partition(dist, consts.max_features + 1, axis=1)[:, :consts.max_features + 1:], axis=1)[:, 1::])\n",
    "    \n",
    "    if mode == 'train':\n",
    "        targets = np.array(lib.train_data[lib.train_data.group_id == group_id].target)\n",
    "        np.save(lib.target_path(group_id), targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@logger\n",
    "def process_data(mode):\n",
    "    if mode == 'train':\n",
    "        arange = lib.g_arange['train']\n",
    "        for group_id in arange:\n",
    "            export_data(mode, group_id)\n",
    "            \n",
    "    elif mode == 'test':\n",
    "        arange = lib.g_arange['test']\n",
    "        for group_id in arange:\n",
    "            export_data(mode, group_id)\n",
    "            \n",
    "    elif mode == 'all':\n",
    "        process_data('train')\n",
    "        process_data('test')\n",
    "        \n",
    "    else:\n",
    "        raise ValueError('wrong mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@logger\n",
    "def import_data(mode):\n",
    "    if mode == 'train':\n",
    "        arange = lib.g_arange['train']\n",
    "        targets = np.load(lib.target_path(arange[0]))\n",
    "        features = np.load(lib.features_path(arange[0]))\n",
    "        \n",
    "        for group_id in arange[1::]:\n",
    "            group_targets = np.load(lib.target_path(group_id))\n",
    "            group_features = np.load(lib.features_path(group_id))\n",
    "\n",
    "            targets = np.concatenate((targets, group_targets))\n",
    "            features = np.concatenate((features, group_features))\n",
    "            \n",
    "        return features, targets\n",
    "    \n",
    "    elif mode == 'test':\n",
    "        arange = lib.g_arange['test']\n",
    "        features = np.load(lib.features_path(arange[0]))\n",
    "        \n",
    "        for group_id in arange[1::]:\n",
    "            group_features = np.load(lib.features_path(group_id))\n",
    "            features = np.concatenate((features, group_features))\n",
    "            \n",
    "        return features\n",
    "    \n",
    "    elif mode == 'all':\n",
    "        train_data = import_data('train')\n",
    "        test_data = import_data('test')\n",
    "        return train_data[0], train_data[1], test_data\n",
    "    \n",
    "    else:\n",
    "        raise ValueError('wrong mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49min 1s, sys: 1min, total: 50min 2s\n",
      "Wall time: 53min 5s\n"
     ]
    }
   ],
   "source": [
    "%time process_data('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 363 ms, sys: 239 ms, total: 602 ms\n",
      "Wall time: 888 ms\n"
     ]
    }
   ],
   "source": [
    "%time X_train, y_train, X_test = import_data('all')\n",
    "!cat data/report.logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "data_train, data_test, label_train, label_test = model_selection.train_test_split(X_train,\n",
    "                                                                                  y_train,\n",
    "                                                                                  test_size=0.1,\n",
    "                                                                                  stratify=y_train)\n",
    "data_train = scaler.transform(data_train)\n",
    "data_test = scaler.transform(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7264833574529667"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.SGDClassifier(loss='log',\n",
    "                                   penalty='l1',\n",
    "                                   alpha=0.005,\n",
    "                                   l1_ratio=0.01,\n",
    "                                   max_iter=10000,\n",
    "                                   n_jobs=-1,\n",
    "                                   n_iter_no_change=1,\n",
    "                                   class_weight='balanced')\n",
    "model.fit(data_train, label_train)\n",
    "metrics.f1_score(label_test, model.predict(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7336010709504684"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(kernel='rbf',\n",
    "            max_iter=-1,\n",
    "            gamma='scale',\n",
    "            probability=True,\n",
    "            tol=1e-3,\n",
    "            class_weight='balanced')\n",
    "model.fit(data_train, label_train)\n",
    "\n",
    "pred_proba = model.predict_proba(data_test)\n",
    "prediction = [int(x[1] > consts.threshold) for x in pred_proba]\n",
    "\n",
    "metrics.f1_score(label_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_test)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "pred_proba = model.predict_proba(X_test)\n",
    "prediction = [int(x[1] > consts.threshold) for x in pred_proba]\n",
    "\n",
    "# prediction = model.predict(X_test)\n",
    "\n",
    "with open('submission.csv', 'w') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=['pair_id', 'target'])\n",
    "    writer.writeheader()\n",
    "    i = 11691\n",
    "    for elem in prediction:\n",
    "        writer.writerow({'pair_id': str(i), 'target': str(elem)})\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
